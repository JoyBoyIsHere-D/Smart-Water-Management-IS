{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d00cc0",
   "metadata": {},
   "source": [
    "# Federated Learning for Water Quality Prediction\n",
    "\n",
    "This notebook demonstrates how to implement federated learning on the water quality dataset using the Flower framework. Federated learning allows training machine learning models across multiple decentralized devices without sharing raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb8f73",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "\n",
    "Install necessary libraries for federated learning implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219b8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries if not already installed\n",
    "#%pip install \"flwr[simulation]\" tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fe6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc1529",
   "metadata": {},
   "source": [
    "## 2. Prepare Federated Data\n",
    "\n",
    "Load the dataset and simulate decentralized data across multiple clients (devices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56658be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "unsafe\n",
      "0    7790\n",
      "1     850\n",
      "Name: count, dtype: int64\n",
      "Percentage unsafe: 9.84%\n",
      "Simulated 5 federated clients from the dataset\n",
      "Federated data prepared!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('synthetic_dataset.csv')\n",
    "\n",
    "# Create target variable: 1 if unsafe (has alerts or abnormal readings), 0 if safe\n",
    "def create_target(row):\n",
    "    # Check for explicit alerts (alert column is not NaN)\n",
    "    if pd.notna(row['alert']):\n",
    "        return 1\n",
    "    \n",
    "    # Check for abnormal sensor statuses\n",
    "    if row['pressure_status'] in ['High', 'Low']:\n",
    "        return 1\n",
    "    if row['tds_status'] == 'Poor':\n",
    "        return 1\n",
    "    if row['ph_status'] in ['Acidic', 'Alkaline']:\n",
    "        return 1\n",
    "    if row['sensor_status'] == 'Fault':\n",
    "        return 1\n",
    "    \n",
    "    # If none of the above, consider it safe\n",
    "    return 0\n",
    "\n",
    "df['unsafe'] = df.apply(create_target, axis=1)\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df['unsafe'].value_counts())\n",
    "print(f\"Percentage unsafe: {df['unsafe'].mean()*100:.2f}%\")\n",
    "\n",
    "# Select features\n",
    "numerical_cols = ['pressure_bar', 'flow_rate_L_min', 'total_volume_L', 'tds_ppm', 'ph', 'temperature_C', 'signal_strength_dBm']\n",
    "categorical_cols = ['pressure_status', 'tds_status', 'ph_status', 'wifi_status', 'sensor_status']\n",
    "\n",
    "# Preprocess\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Features list\n",
    "features = numerical_cols + [col for col in df_encoded.columns if col.startswith(tuple(categorical_cols)) and col != 'alert']\n",
    "\n",
    "# Since we only have one device, simulate multiple clients by splitting the data randomly\n",
    "num_clients = 5\n",
    "client_data = {}\n",
    "\n",
    "# Shuffle the data\n",
    "df_shuffled = df_encoded.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split into clients\n",
    "samples_per_client = len(df_shuffled) // num_clients\n",
    "\n",
    "for i in range(num_clients):\n",
    "    start_idx = i * samples_per_client\n",
    "    end_idx = (i + 1) * samples_per_client if i < num_clients - 1 else len(df_shuffled)\n",
    "    client_df = df_shuffled.iloc[start_idx:end_idx]\n",
    "    \n",
    "    X = client_df[features]\n",
    "    y = client_df['unsafe']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    client_data[f'client_{i}'] = {\n",
    "        'X_train': X_train.values.astype(np.float32),\n",
    "        'X_test': X_test.values.astype(np.float32),\n",
    "        'y_train': y_train.values.astype(np.float32),\n",
    "        'y_test': y_test.values.astype(np.float32)\n",
    "    }\n",
    "\n",
    "print(f\"Simulated {num_clients} federated clients from the dataset\")\n",
    "print(\"Federated data prepared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a87b8",
   "metadata": {},
   "source": [
    "## 3. Define the Global Model\n",
    "\n",
    "Create a neural network model that will be trained across federated clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adec576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,185</span> (4.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,185\u001b[0m (4.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,185</span> (4.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,185\u001b[0m (4.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(len(features),),\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model\n",
    "\n",
    "# Create global model\n",
    "global_model = create_model()\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023b7e4",
   "metadata": {},
   "source": [
    "## 4. Set Up Federated Learning Clients\n",
    "\n",
    "Define Flower clients that will train locally on their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc4a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 federated clients\n"
     ]
    }
   ],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, client_id, data):\n",
    "        self.client_id = client_id\n",
    "        self.data = data\n",
    "        self.model = create_model()\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "        # Local training with early stopping to prevent overfitting\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True,\n",
    "                                   min_delta=0.001)\n",
    "        history = self.model.fit(\n",
    "            self.data['X_train'], self.data['y_train'],\n",
    "            epochs=20, batch_size=32, validation_split=0.2,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "        return self.model.get_weights(), len(self.data['X_train']), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, accuracy, precision, recall = self.model.evaluate(self.data['X_test'], self.data['y_test'], verbose=0)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return loss, len(self.data['X_test']), {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score\n",
    "        }\n",
    "\n",
    "# Create clients\n",
    "clients = []\n",
    "for i, (device_id, data) in enumerate(client_data.items()):\n",
    "    client = FlowerClient(f\"client_{i}\", data)\n",
    "    clients.append(client)\n",
    "\n",
    "print(f\"Created {len(clients)} federated clients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b66710",
   "metadata": {},
   "source": [
    "## 5. Implement Federated Averaging\n",
    "\n",
    "Set up the federated learning strategy with FedAvg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84941cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> fl.client.Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    # Create a Flower client using the client_id\n",
    "    client_id = int(cid)\n",
    "    if client_id < len(clients):\n",
    "        return clients[client_id]\n",
    "    else:\n",
    "        raise ValueError(f\"Client {client_id} not available\")\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=1.0,  # Sample 100% of available clients for evaluation\n",
    "    min_fit_clients=len(clients),  # Never sample fewer than this number of clients for training\n",
    "    min_evaluate_clients=len(clients),  # Never sample fewer than this number of clients for evaluation\n",
    "    min_available_clients=len(clients),  # Wait until all clients are available\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346aef21",
   "metadata": {},
   "source": [
    "## 6. Train the Model Federally\n",
    "\n",
    "Run the federated training simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1112c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating federated learning rounds...\n",
      "\n",
      "--- Round 1 ---\n",
      "Client client_0: Acc=0.9075, Prec=1.0000, Rec=0.0588, F1=0.1111\n",
      "Client client_1: Acc=0.9740, Prec=1.0000, Rec=0.7500, F1=0.8571\n",
      "Client client_2: Acc=0.9740, Prec=1.0000, Rec=0.7188, F1=0.8364\n",
      "Client client_3: Acc=0.9451, Prec=1.0000, Rec=0.4571, F1=0.6275\n",
      "Client client_4: Acc=0.9595, Prec=1.0000, Rec=0.5758, F1=0.7308\n",
      "Round 1 average: Acc=0.9520, F1=0.6326\n",
      "\n",
      "--- Round 2 ---\n",
      "Client client_0: Acc=0.9942, Prec=1.0000, Rec=0.9412, F1=0.9697\n",
      "Client client_1: Acc=0.9971, Prec=1.0000, Rec=0.9722, F1=0.9859\n",
      "Client client_2: Acc=0.9971, Prec=1.0000, Rec=0.9688, F1=0.9841\n",
      "Client client_3: Acc=0.9913, Prec=1.0000, Rec=0.9143, F1=0.9552\n",
      "Client client_4: Acc=0.9971, Prec=1.0000, Rec=0.9697, F1=0.9846\n",
      "Round 2 average: Acc=0.9954, F1=0.9759\n",
      "\n",
      "--- Round 3 ---\n",
      "Client client_0: Acc=0.9942, Prec=1.0000, Rec=0.9412, F1=0.9697\n",
      "Client client_1: Acc=0.9971, Prec=1.0000, Rec=0.9722, F1=0.9859\n",
      "Client client_2: Acc=0.9971, Prec=1.0000, Rec=0.9688, F1=0.9841\n",
      "Client client_3: Acc=0.9971, Prec=1.0000, Rec=0.9714, F1=0.9855\n",
      "Client client_4: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "Round 3 average: Acc=0.9971, F1=0.9850\n",
      "\n",
      "--- Round 4 ---\n",
      "Client client_0: Acc=0.9942, Prec=1.0000, Rec=0.9412, F1=0.9697\n",
      "Client client_1: Acc=0.9971, Prec=1.0000, Rec=0.9722, F1=0.9859\n",
      "Client client_2: Acc=0.9971, Prec=1.0000, Rec=0.9688, F1=0.9841\n",
      "Client client_3: Acc=0.9971, Prec=1.0000, Rec=0.9714, F1=0.9855\n",
      "Client client_4: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "Round 4 average: Acc=0.9971, F1=0.9850\n",
      "\n",
      "--- Round 5 ---\n",
      "Client client_0: Acc=0.9942, Prec=1.0000, Rec=0.9412, F1=0.9697\n",
      "Client client_1: Acc=0.9971, Prec=1.0000, Rec=0.9722, F1=0.9859\n",
      "Client client_2: Acc=0.9971, Prec=1.0000, Rec=0.9688, F1=0.9841\n",
      "Client client_3: Acc=0.9971, Prec=1.0000, Rec=0.9714, F1=0.9855\n",
      "Client client_4: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "Round 5 average: Acc=0.9971, F1=0.9850\n",
      "\n",
      "Federated learning simulation completed!\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, let's simulate federated learning manually\n",
    "# In a real setup, you'd run clients and server separately\n",
    "\n",
    "print(\"Simulating federated learning rounds...\")\n",
    "\n",
    "# Initialize global model\n",
    "global_model = create_model()\n",
    "global_weights = global_model.get_weights()\n",
    "\n",
    "num_rounds = 5  # More rounds for better convergence\n",
    "\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"\\n--- Round {round_num + 1} ---\")\n",
    "\n",
    "    # Collect weights from all clients\n",
    "    client_weights = []\n",
    "    round_metrics = []\n",
    "\n",
    "    for client in clients:\n",
    "        # Simulate local training\n",
    "        client.model.set_weights(global_weights)\n",
    "\n",
    "        # Local training\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, min_delta=0.001)\n",
    "        history = client.model.fit(\n",
    "            client.data['X_train'], client.data['y_train'],\n",
    "            epochs=20, batch_size=32, validation_split=0.2,\n",
    "            callbacks=[early_stop], verbose=0\n",
    "        )\n",
    "\n",
    "        client_weights.append(client.model.get_weights())\n",
    "\n",
    "        # Evaluate locally\n",
    "        loss, accuracy, precision, recall = client.model.evaluate(client.data['X_test'], client.data['y_test'], verbose=0)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        round_metrics.append({\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score\n",
    "        })\n",
    "        print(f\"Client {client.client_id}: Acc={accuracy:.4f}, Prec={precision:.4f}, Rec={recall:.4f}, F1={f1_score:.4f}\")\n",
    "\n",
    "    # Federated averaging (simple average)\n",
    "    new_weights = []\n",
    "    for layer_weights in zip(*client_weights):\n",
    "        # Average weights across clients\n",
    "        avg_weights = np.mean(layer_weights, axis=0)\n",
    "        new_weights.append(avg_weights)\n",
    "\n",
    "    # Update global model\n",
    "    global_weights = new_weights\n",
    "    global_model.set_weights(global_weights)\n",
    "\n",
    "    # Print round summary\n",
    "    avg_metrics = {k: np.mean([m[k] for m in round_metrics]) for k in round_metrics[0].keys()}\n",
    "    print(f\"Round {round_num + 1} average: Acc={avg_metrics['accuracy']:.4f}, F1={avg_metrics['f1_score']:.4f}\")\n",
    "\n",
    "print(\"\\nFederated learning simulation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f8d8e",
   "metadata": {},
   "source": [
    "## 7. Evaluate Federated Model Performance\n",
    "\n",
    "Test the trained global model on a held-out dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318af5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model Performance:\n",
      "Accuracy: 0.9971\n",
      "Precision: 1.0000\n",
      "Recall: 0.9706\n",
      "F1-Score: 0.9851\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Test set class distribution: [1560  170]\n",
      "Predicted class distribution: [1565  165]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Safe       1.00      1.00      1.00      1560\n",
      "      Unsafe       1.00      0.97      0.99       170\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      0.99      0.99      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "\n",
      "Federated learning completed successfully!\n",
      "The model now predicts water quality as Safe (0) or Unsafe (1)\n"
     ]
    }
   ],
   "source": [
    "# After federated training, the global model weights are updated\n",
    "# For evaluation, we can use one of the clients or create a test set\n",
    "\n",
    "# Create a global test set from all devices\n",
    "all_X_test = np.concatenate([client_data[device]['X_test'] for device in client_data.keys()])\n",
    "all_y_test = np.concatenate([client_data[device]['y_test'] for device in client_data.keys()])\n",
    "\n",
    "# Evaluate the global model\n",
    "loss, accuracy, precision, recall = global_model.evaluate(all_X_test, all_y_test, verbose=0)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"Global Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = (global_model.predict(all_X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Check unique classes\n",
    "unique_classes = np.unique(all_y_test)\n",
    "print(f\"\\nTest set class distribution: {np.bincount(all_y_test.astype(int))}\")\n",
    "print(f\"Predicted class distribution: {np.bincount(y_pred)}\")\n",
    "\n",
    "if len(unique_classes) > 1:\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_y_test, y_pred, target_names=['Safe', 'Unsafe']))\n",
    "else:\n",
    "    print(f\"Only one class present in test data: {unique_classes[0]}\")\n",
    "\n",
    "print(\"\\nFederated learning completed successfully!\")\n",
    "print(\"The model now predicts water quality as Safe (0) or Unsafe (1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7c4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'federated_water_quality_model.h5'\n",
      "Scaler saved as 'water_quality_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained federated model\n",
    "global_model.save('federated_water_quality_model.h5')\n",
    "print(\"Model saved as 'federated_water_quality_model.h5'\")\n",
    "\n",
    "# Save the scaler for future predictions\n",
    "import joblib\n",
    "joblib.dump(scaler, 'water_quality_scaler.pkl')\n",
    "print(\"Scaler saved as 'water_quality_scaler.pkl'\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"FEDERATED LEARNING SUMMARY\")\n",
    "# print(\"=\"*50)\n",
    "# print(\"✅ Fixed overfitting issue by correcting target variable logic\")\n",
    "# print(\"✅ Added L2 regularization and dropout to prevent overfitting\")\n",
    "# print(\"✅ Implemented proper evaluation metrics (Precision, Recall, F1)\")\n",
    "# print(\"✅ Balanced dataset: 90.16% Safe, 9.84% Unsafe\")\n",
    "# print(\"✅ Final model performance:\")\n",
    "# print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"   Precision: {precision:.4f}\")\n",
    "# print(f\"   Recall: {recall:.4f}\")\n",
    "# print(f\"   F1-Score: {f1_score:.4f}\")\n",
    "# print(\"✅ Model predicts: 0 = Safe water, 1 = Unsafe water\")\n",
    "# print(\"✅ Ready for deployment in federated IoT water monitoring system\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
